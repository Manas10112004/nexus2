import streamlit as st
import uuid
import matplotlib.pyplot as plt
import os
import io  # --- NEW: For handling byte streams ---
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

# --- CUSTOM MODULES ---
from nexus_db import init_db, save_message, load_history, clear_session, get_all_sessions, save_setting, load_setting
from themes import THEMES, inject_theme_css
from nexus_engine import DataEngine
from nexus_brain import build_agent_graph, get_key_status

# --- NEW MODULES ---
from nexus_security import check_password, logout
from nexus_report import generate_pdf
from nexus_voice import transcribe_audio
from streamlit_mic_recorder import mic_recorder  # --- NEW: Import specific recorder ---

# --- UI CONFIG ---
st.set_page_config(page_title="Nexus AI", layout="wide", page_icon="‚ö°")

# --- 1. SECURITY GATE ---
if not check_password():
    st.stop()

init_db()

# --- INITIALIZE STATE ---
if "data_engine" not in st.session_state: st.session_state.data_engine = DataEngine()
engine = st.session_state.data_engine

if "current_session_id" not in st.session_state:
    st.session_state.current_session_id = f"Session-{uuid.uuid4().hex[:4]}"
current_sess = st.session_state.current_session_id

# --- BUILD BRAIN ---
app = build_agent_graph(engine)

# --- SIDEBAR ---
current_theme = load_setting("theme", "üåø Eywa (Avatar)")
inject_theme_css(current_theme)
theme_data = THEMES.get(current_theme, THEMES["üåø Eywa (Avatar)"])

with st.sidebar:
    st.title("‚öôÔ∏è NEXUS HQ")
    st.caption(get_key_status())

    if st.button("üîí Logout", use_container_width=True):
        logout()

    st.divider()

    # --- 2. VOICE MODE (FIXED) ---
    st.markdown("### üéôÔ∏è Voice Command")

    # Using streamlit-mic-recorder for "Click -> Speak" flow
    # This widget returns a dictionary containing audio bytes
    voice_data = mic_recorder(
        start_prompt="üé§ Start Recording",
        stop_prompt="‚èπÔ∏è Stop Recording",
        just_once=True,
        use_container_width=True,
        format="wav",
        key="voice_recorder"
    )

    voice_text = ""

    # Logic to handle recording
    if voice_data:
        # We use spinner (transient) instead of status (persistent) to fix the "never stops" bug
        with st.spinner("üéß Processing Voice..."):
            # Convert raw bytes to a file-like object for the existing transcriber
            audio_bio = io.BytesIO(voice_data['bytes'])
            audio_bio.name = "audio.wav"

            # Send to Groq/Whisper
            voice_text = transcribe_audio(audio_bio)

        if voice_text:
            st.success(f"**Recognized:** \"{voice_text}\"")
        else:
            st.warning("No speech detected.")

    st.divider()

    uploaded_file = st.file_uploader("üìÇ Upload File", type=None)
    if uploaded_file:
        status = engine.load_file(uploaded_file)
        if "Error" in status:
            st.error(status)
        else:
            st.success(status)

    if st.button("üßπ Clear Plots", use_container_width=True):
        plt.clf()
        engine.latest_figure = None
        if os.path.exists("temp_chart.png"): os.remove("temp_chart.png")
        st.success("Plots cleared.")

    st.divider()

    # --- 3. SMART REPORTING ---
    st.markdown("### üìÑ Reporting")
    if st.button("üì• Export PDF Report", use_container_width=True):
        with st.spinner("Compiling PDF..."):
            history = load_history(current_sess)
            pdf_file = generate_pdf(history, current_sess)
        with open(pdf_file, "rb") as f:
            st.download_button("‚¨áÔ∏è Download PDF", f, file_name=pdf_file, use_container_width=True)

    st.divider()

    st.markdown("### üïí Session History")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("‚ûï New", use_container_width=True):
            st.session_state.current_session_id = f"Session-{uuid.uuid4().hex[:4]}"
            st.rerun()
    with col2:
        if st.button("üóëÔ∏è Clear", use_container_width=True):
            clear_session(current_sess)
            st.rerun()

    # List recent sessions
    st.caption("Recent Sessions:")
    for s in get_all_sessions()[:5]:
        if st.button(f"üìÇ {s}", key=s, use_container_width=True):
            st.session_state.current_session_id = s
            st.rerun()

# --- CHAT INTERFACE ---
st.title(f"NEXUS // {current_theme.split(' ')[1].upper()}")

# Load History
history = load_history(current_sess)
for msg in history:
    role = "user" if msg["role"] == "user" else "assistant"
    with st.chat_message(role, avatar=theme_data["user_avatar"] if role == "user" else theme_data["ai_avatar"]):
        st.markdown(msg["content"])

# --- INPUT HANDLING ---
user_input = st.chat_input("Enter command...")

prompt = None
# Prioritize Voice if valid
if voice_text and not voice_text.startswith("["):
    prompt = voice_text
elif user_input:
    prompt = user_input

if prompt:
    with st.chat_message("user", avatar=theme_data["user_avatar"]):
        st.markdown(prompt)
    save_message(current_sess, "user", prompt)

    # Refresh Cheatsheet
    if engine.df is not None and not engine.column_str:
        engine.column_str = ", ".join(list(engine.df.columns))

    # --- SYSTEM PROMPT (Robust & Flexible) ---
    system_text = "You are Nexus, an advanced data analysis AI. You have access to a Python environment."
    has_data = "df" in engine.scope

    if has_data:
        system_text += f"""
        [DATA MODE ACTIVE]
        1. Variable 'df' is loaded.
        2. VALID COLUMNS: [{engine.column_str}]
        3. Use 'python_analysis' for all data queries.
        """
    else:
        system_text += """
        [SANDBOX MODE ACTIVE]
        1. No file loaded.
        2. You can still use 'python_analysis' to:
           - Generate synthetic data.
           - Perform math calculations.
        3. If asked for real-world facts/news, use 'tavily'.
        """

    # Memory Window
    recent_history = history[-6:]

    messages = [SystemMessage(content=system_text)] + \
               [HumanMessage(content=m["content"]) if m["role"] == "user" else AIMessage(content=m["content"]) for m in
                recent_history] + \
               [HumanMessage(content=prompt)]

    # Run Agent
    with st.chat_message("assistant", avatar=theme_data["ai_avatar"]):
        status_box = st.status("Processing...", expanded=True)
        try:
            final_resp = ""
            for event in app.stream({"messages": messages}, config={"recursion_limit": 10}, stream_mode="values"):
                msg = event["messages"][-1]

                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    for t in msg.tool_calls:
                        status_box.write(f"‚öôÔ∏è Calling: `{t['name']}`")

                if isinstance(msg, AIMessage) and msg.content and not msg.tool_calls:
                    final_resp = msg.content

            # 1. Render Chart
            if engine.latest_figure:
                st.pyplot(engine.latest_figure)
                chart_path = f"chart_{current_sess}.png"
                engine.latest_figure.savefig(chart_path)
                engine.latest_figure = None

            # 2. Render Text
            if final_resp:
                st.markdown(final_resp)
                status_box.update(label="Complete", state="complete", expanded=False)
                save_message(current_sess, "assistant", final_resp)
            else:
                status_box.update(label="Complete", state="complete", expanded=False)

        except Exception as e:
            status_box.update(label="Error", state="error")
            st.error(f"Error: {e}")